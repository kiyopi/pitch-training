'use client';

import { useState, useRef, useCallback, useEffect } from 'react';
import * as Tone from 'tone';
import { PitchDetector } from 'pitchy';

// AudioSystemPhase enum (from /test/separated-audio/)
export enum AudioSystemPhase {
  IDLE = 'idle',
  TRANSITIONING = 'transitioning',
  BASE_TONE_PHASE = 'base_tone',
  SCORING_PHASE = 'scoring',
  ERROR_STATE = 'error'
}

// å€éŸ³è£œæ­£è¨­å®šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆ/test/separated-audio/ç§»æ¤ï¼‰
export interface HarmonicCorrectionConfig {
  fundamentalSearchRange: number;    // åŸºéŸ³æ¢ç´¢ç¯„å›²ï¼ˆÂ±50Hzï¼‰
  harmonicRatios: number[];          // å€éŸ³æ¯”ç‡ [0.5, 2.0, 3.0, 4.0]
  confidenceThreshold: number;       // ç¢ºä¿¡åº¦ã—ãã„å€¤ï¼ˆ0.8ï¼‰
  stabilityBuffer: number[];         // å®‰å®šåŒ–ãƒãƒƒãƒ•ã‚¡ï¼ˆéå»5ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
  vocalRange: { min: number, max: number }; // äººé–“éŸ³åŸŸï¼ˆ130-1047Hz, C3-C6ï¼‰
}

// AudioEngineè¨­å®šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
export interface AudioEngineConfig {
  mode: 'random' | 'continuous' | 'chromatic';
  enablePitchDetection: boolean;
  enableHarmonicCorrection: boolean;
  baseNotes: string[];
  harmonicConfig?: Partial<HarmonicCorrectionConfig>;
}

// AudioEngineæˆ»ã‚Šå€¤ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
export interface AudioEngineReturn {
  // åŸºéŸ³å†ç”Ÿæ©Ÿèƒ½
  playBaseTone: (note: string) => Promise<void>;
  stopBaseTone: () => void;
  
  // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³æ©Ÿèƒ½
  startPitchDetection: () => Promise<void>;
  stopPitchDetection: () => void;
  
  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º
  currentPitch: number | null;
  correctedPitch: number | null;
  confidence: number;
  
  // çŠ¶æ…‹ç®¡ç†
  isPlaying: boolean;
  phase: AudioSystemPhase;
  error: string | null;
}

// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€éŸ³è£œæ­£è¨­å®šï¼ˆ/test/separated-audio/æº–æ‹ ï¼‰
const DEFAULT_HARMONIC_CONFIG: HarmonicCorrectionConfig = {
  fundamentalSearchRange: 50,
  harmonicRatios: [0.5, 2.0, 3.0, 4.0],  // 1/2å€éŸ³, 2å€éŸ³, 3å€éŸ³, 4å€éŸ³
  confidenceThreshold: 0.8,
  stabilityBuffer: [],
  vocalRange: { min: 130.81, max: 1046.50 } // C3-C6
};

// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
const DEFAULT_CONFIG: AudioEngineConfig = {
  mode: 'random',
  enablePitchDetection: false,
  enableHarmonicCorrection: false,
  baseNotes: ['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5', 'D5', 'E5']
};

/**
 * useAudioEngine Hook
 * éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ çµ±åˆHook - Tone.js + Pitchy + å€éŸ³è£œæ­£ã®çµ±åˆç®¡ç†
 */
export function useAudioEngine(config: Partial<AudioEngineConfig> = {}): AudioEngineReturn {
  // è¨­å®šã®çµ±åˆ
  const mergedConfig = { ...DEFAULT_CONFIG, ...config };
  const harmonicConfig = { ...DEFAULT_HARMONIC_CONFIG, ...config.harmonicConfig };
  
  // åŸºæœ¬çŠ¶æ…‹ç®¡ç†
  const [isPlaying, setIsPlaying] = useState(false);
  const [phase, setPhase] = useState<AudioSystemPhase>(AudioSystemPhase.IDLE);
  const [error, setError] = useState<string | null>(null);
  
  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡ºãƒ‡ãƒ¼ã‚¿
  const [currentPitch, setCurrentPitch] = useState<number | null>(null);
  const [correctedPitch, setCorrectedPitch] = useState<number | null>(null);
  const [confidence, setConfidence] = useState<number>(0);
  
  // Refç®¡ç†
  const configRef = useRef(mergedConfig);
  const harmonicConfigRef = useRef(harmonicConfig);
  const samplerRef = useRef<Tone.Sampler | null>(null);
  const isInitializedRef = useRef(false);
  
  // Pitchyçµ±åˆç”¨ã®Ref
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const pitchDetectorRef = useRef<PitchDetector<Float32Array> | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const [isMicInitialized, setIsMicInitialized] = useState(false);
  
  // å€éŸ³è£œæ­£ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®Refï¼ˆ/test/separated-audio/ç§»æ¤ï¼‰
  const previousFrequencyRef = useRef<number | null>(null);
  const frequencyHistoryRef = useRef<number[]>([]);
  const stabilityBufferRef = useRef<number[]>([]);
  
  // è¨­å®šæ›´æ–°
  configRef.current = mergedConfig;
  harmonicConfigRef.current = harmonicConfig;
  
  // ã‚¨ãƒ©ãƒ¼å‡¦ç†
  const handleError = useCallback((errorMessage: string) => {
    console.error('[useAudioEngine]', errorMessage);
    setError(errorMessage);
    setPhase(AudioSystemPhase.ERROR_STATE);
  }, []);
  
  // ã‚¨ãƒ©ãƒ¼ã‚¯ãƒªã‚¢
  const clearError = useCallback(() => {
    setError(null);
    if (phase === AudioSystemPhase.ERROR_STATE) {
      setPhase(AudioSystemPhase.IDLE);
    }
  }, [phase]);

  // Tone.js Salamander PianoåˆæœŸåŒ–
  const initializeSampler = useCallback(async (): Promise<void> => {
    try {
      if (isInitializedRef.current && samplerRef.current) {
        return; // æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿
      }

      console.log('[useAudioEngine] Salamander PianoåˆæœŸåŒ–é–‹å§‹');
      
      // AudioContexté–‹å§‹
      if (Tone.getContext().state !== 'running') {
        await Tone.start();
        console.log('[useAudioEngine] AudioContexté–‹å§‹å®Œäº†');
      }

      // Salamander Pianoè¨­å®šï¼ˆæ—¢å­˜3ãƒ¢ãƒ¼ãƒ‰äº’æ›ï¼‰
      const sampler = new Tone.Sampler({
        urls: {
          "C4": "C4.mp3"
        },
        baseUrl: "https://tonejs.github.io/audio/salamander/",
        release: 1.5,         // æ—¢å­˜çµ±ä¸€è¨­å®š
        volume: 6             // iPhoneæœ€é©åŒ–è¨­å®š
      }).toDestination();

      // éŸ³æºèª­ã¿è¾¼ã¿å¾…æ©Ÿ
      console.log('[useAudioEngine] ãƒ”ã‚¢ãƒéŸ³æºèª­ã¿è¾¼ã¿ä¸­...');
      await Tone.loaded();
      console.log('[useAudioEngine] ãƒ”ã‚¢ãƒéŸ³æºèª­ã¿è¾¼ã¿å®Œäº†');

      samplerRef.current = sampler;
      isInitializedRef.current = true;
      
    } catch (err) {
      handleError(`Salamander PianoåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: ${err}`);
      throw err;
    }
  }, [handleError]);

  // samplerç ´æ£„ãƒ»ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
  const disposeSampler = useCallback(() => {
    try {
      if (samplerRef.current) {
        console.log('[useAudioEngine] samplerç ´æ£„');
        samplerRef.current.dispose();
        samplerRef.current = null;
      }
      isInitializedRef.current = false;
    } catch (err) {
      console.error('[useAudioEngine] samplerç ´æ£„ã‚¨ãƒ©ãƒ¼:', err);
    }
  }, []);

  // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒ»Web Audio APIåˆæœŸåŒ–
  const initializeMicrophone = useCallback(async (): Promise<void> => {
    try {
      if (!configRef.current.enablePitchDetection) {
        console.log('[useAudioEngine] éŸ³ç¨‹æ¤œå‡ºç„¡åŠ¹ï¼ˆè¨­å®šã«ã‚ˆã‚Šï¼‰');
        return;
      }

      if (isMicInitialized && audioContextRef.current && pitchDetectorRef.current) {
        console.log('[useAudioEngine] ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿');
        return;
      }

      console.log('[useAudioEngine] ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–é–‹å§‹');

      // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‚¢ã‚¯ã‚»ã‚¹è¦æ±‚ï¼ˆ/test/separated-audio/è¨­å®šæº–æ‹ ï¼‰
      streamRef.current = await navigator.mediaDevices.getUserMedia({
        audio: {
          autoGainControl: false,
          echoCancellation: false,
          noiseSuppression: false,
          sampleRate: 44100,
          channelCount: 1
        }
      });

      // Web Audio API AudioContextä½œæˆ
      audioContextRef.current = new AudioContext({ sampleRate: 44100 });
      
      // MediaStreamSourceNodeä½œæˆ
      const source = audioContextRef.current.createMediaStreamSource(streamRef.current);
      
      // AnalyserNodeä½œæˆãƒ»è¨­å®š
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 16384; // /test/separated-audio/æº–æ‹ 
      analyserRef.current.smoothingTimeConstant = 0.3;
      
      // æ¥ç¶š
      source.connect(analyserRef.current);
      
      // PitchDetectoråˆæœŸåŒ–ï¼ˆMcLeod Pitch Methodï¼‰
      pitchDetectorRef.current = PitchDetector.forFloat32Array(analyserRef.current.fftSize);
      pitchDetectorRef.current.clarityThreshold = 0.15; // /test/separated-audio/æº–æ‹ 

      setIsMicInitialized(true);
      console.log('[useAudioEngine] ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†');

    } catch (err) {
      handleError(`ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: ${err}`);
      throw err;
    }
  }, [handleError, isMicInitialized]);

  // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒ»ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
  const disposeMicrophone = useCallback(() => {
    try {
      console.log('[useAudioEngine] ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾');
      
      // animationFrameåœæ­¢
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
      
      // MediaStreamåœæ­¢
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      
      // AudioContexté–‰ã˜ã‚‹
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close();
        audioContextRef.current = null;
      }
      
      // Refãƒ»StateåˆæœŸåŒ–
      analyserRef.current = null;
      pitchDetectorRef.current = null;
      setIsMicInitialized(false);
      setCurrentPitch(null);
      setCorrectedPitch(null);
      setConfidence(0);
      
      // å€éŸ³è£œæ­£ã‚·ã‚¹ãƒ†ãƒ ã®å®Œå…¨ãƒªã‚»ãƒƒãƒˆ
      previousFrequencyRef.current = null;
      frequencyHistoryRef.current = [];
      stabilityBufferRef.current = [];
      
    } catch (err) {
      console.error('[useAudioEngine] ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾ã‚¨ãƒ©ãƒ¼:', err);
    }
  }, []);

  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³ç¨‹æ¤œå‡ºãƒ«ãƒ¼ãƒ—ï¼ˆé–¢æ•°ã®å®šç¾©é †åºã‚’ä¿®æ­£ï¼‰
  const startPitchDetectionLoop = useCallback(() => {
    if (!audioContextRef.current || !analyserRef.current || !pitchDetectorRef.current) {
      console.error('[useAudioEngine] éŸ³ç¨‹æ¤œå‡º: å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæœªåˆæœŸåŒ–');
      return;
    }

    const analyser = analyserRef.current;
    const detector = pitchDetectorRef.current;
    const audioContext = audioContextRef.current;
    const float32Array = new Float32Array(analyser.fftSize);

    const detectPitch = () => {
      // éŸ³ç¨‹æ¤œå‡ºãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹ã‹ã€ãƒã‚¤ã‚¯ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã¯åœæ­¢
      if (!audioContextRef.current || !analyserRef.current || !pitchDetectorRef.current) {
        animationFrameRef.current = null;
        return;
      }

      // ãƒ•ã‚§ãƒ¼ã‚ºãƒã‚§ãƒƒã‚¯
      if (phase !== AudioSystemPhase.SCORING_PHASE) {
        animationFrameRef.current = null;
        return;
      }

      // å‘¨æ³¢æ•°ãƒ‡ãƒ¼ã‚¿å–å¾—
      analyser.getFloatTimeDomainData(float32Array);
      
      // Pitchy McLeod Pitch Methodå®Ÿè¡Œï¼ˆ/test/separated-audio/æº–æ‹ ï¼‰
      const [frequency, clarity] = detector.findPitch(float32Array, audioContext.sampleRate);
      
      // ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
      if (frequency > 0) {
        console.log(`[useAudioEngine] æ¤œå‡º: ${frequency.toFixed(1)}Hz, clarity: ${clarity.toFixed(3)}`);
      }
      
      if (clarity > 0.15 && frequency > 80 && frequency < 1200) {
        // äººé–“éŸ³åŸŸãƒã‚§ãƒƒã‚¯ï¼ˆ130-1047Hz, C3-C6ï¼‰
        if (frequency >= 130.81 && frequency <= 1046.50) {
          setCurrentPitch(frequency);
          setConfidence(clarity);
          setCorrectedPitch(frequency); // ç¾åœ¨ã¯ãã®ã¾ã¾ï¼ˆå€éŸ³è£œæ­£ã¯å¾Œã§å‡¦ç†ï¼‰
        } else {
          setCurrentPitch(null);
          setConfidence(0);
          setCorrectedPitch(null);
        }
      } else {
        setCurrentPitch(null);
        setConfidence(0);
        setCorrectedPitch(null);
      }

      // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ äºˆç´„ï¼ˆ60fpsç›®æ¨™ï¼‰
      animationFrameRef.current = requestAnimationFrame(detectPitch);
    };

    // æ¤œå‡ºãƒ«ãƒ¼ãƒ—é–‹å§‹
    detectPitch();
  }, [phase]);

  // å€éŸ³è£œæ­£å‡¦ç†ï¼ˆuseEffectã§å®Ÿè¡Œï¼‰
  useEffect(() => {
    if (!configRef.current.enableHarmonicCorrection) {
      return;
    }

    if (currentPitch && currentPitch > 0) {
      // ç°¡æ˜“å€éŸ³è£œæ­£ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
      const candidates = [
        currentPitch,
        currentPitch / 2.0,
        currentPitch / 3.0,
        currentPitch / 4.0,
        currentPitch * 2.0,
      ];

      // äººé–“éŸ³åŸŸå†…ã§æœ€ã‚‚å¦¥å½“ãªå€™è£œã‚’é¸æŠ
      let bestFreq = currentPitch;
      for (const freq of candidates) {
        if (freq >= 130.81 && freq <= 1046.50) {
          // å‰å›ã®å‘¨æ³¢æ•°ã«æœ€ã‚‚è¿‘ã„ã‚‚ã®ã‚’é¸æŠ
          if (previousFrequencyRef.current) {
            const currentDiff = Math.abs(bestFreq - previousFrequencyRef.current);
            const newDiff = Math.abs(freq - previousFrequencyRef.current);
            if (newDiff < currentDiff) {
              bestFreq = freq;
            }
          }
        }
      }

      // å®‰å®šåŒ–ãƒãƒƒãƒ•ã‚¡å‡¦ç†
      stabilityBufferRef.current.push(bestFreq);
      if (stabilityBufferRef.current.length > 5) {
        stabilityBufferRef.current.shift();
      }
      
      const sum = stabilityBufferRef.current.reduce((acc, freq) => acc + freq, 0);
      const stabilizedFreq = sum / stabilityBufferRef.current.length;

      setCorrectedPitch(stabilizedFreq);
      previousFrequencyRef.current = stabilizedFreq;

      if (Math.abs(currentPitch - stabilizedFreq) > 1) {
        console.log(`[useAudioEngine] å€éŸ³è£œæ­£: ${currentPitch.toFixed(1)}Hz â†’ ${stabilizedFreq.toFixed(1)}Hz`);
      }
    }
  }, [currentPitch]);

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆæ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      disposeSampler();
      disposeMicrophone();
    };
  }, [disposeSampler, disposeMicrophone]);
  
  // åŸºéŸ³å†ç”Ÿæ©Ÿèƒ½ï¼ˆTone.jsçµ±åˆå®Ÿè£…ï¼‰
  const playBaseTone = useCallback(async (note: string): Promise<void> => {
    try {
      clearError();
      setPhase(AudioSystemPhase.BASE_TONE_PHASE);
      setIsPlaying(true);
      
      console.log(`[useAudioEngine] playBaseTone: ${note} (mode: ${configRef.current.mode})`);
      
      // Salamander PianoåˆæœŸåŒ–
      await initializeSampler();
      
      if (!samplerRef.current) {
        throw new Error('SampleråˆæœŸåŒ–å¤±æ•—');
      }
      
      // æ—¢å­˜3ãƒ¢ãƒ¼ãƒ‰äº’æ›ã®å†ç”Ÿãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
      console.log(`[useAudioEngine] â™ª å†ç”Ÿä¸­: ${note}`);
      samplerRef.current.triggerAttack(note, undefined, 0.8); // velocityçµ±ä¸€
      
      // å†ç”Ÿæ™‚é–“ã¯å‘¼ã³å‡ºã—å´ã§åˆ¶å¾¡ï¼ˆæ—¢å­˜ãƒ¢ãƒ¼ãƒ‰äº’æ›ï¼‰
      // ã“ã“ã§ã¯å†ç”Ÿé–‹å§‹ã®ã¿å®Ÿè¡Œ
      
    } catch (err) {
      setIsPlaying(false);
      setPhase(AudioSystemPhase.IDLE);
      handleError(`åŸºéŸ³å†ç”Ÿã‚¨ãƒ©ãƒ¼: ${err}`);
    }
  }, [clearError, handleError, initializeSampler]);
  
  // åŸºéŸ³åœæ­¢æ©Ÿèƒ½
  const stopBaseTone = useCallback(() => {
    try {
      console.log('[useAudioEngine] stopBaseTone');
      
      if (samplerRef.current) {
        // å…¨ã¦ã®éŸ³ã‚’åœæ­¢
        samplerRef.current.releaseAll();
        console.log('[useAudioEngine] ğŸ”‡ å†ç”Ÿåœæ­¢');
      }
      
      setIsPlaying(false);
      setPhase(AudioSystemPhase.IDLE);
      
    } catch (err) {
      handleError(`åŸºéŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼: ${err}`);
    }
  }, [handleError]);
  
  // éŸ³ç¨‹æ¤œå‡ºé–‹å§‹ï¼ˆPitchyçµ±åˆå®Ÿè£…ï¼‰
  const startPitchDetection = useCallback(async (): Promise<void> => {
    try {
      if (!configRef.current.enablePitchDetection) {
        console.log('[useAudioEngine] éŸ³ç¨‹æ¤œå‡ºç„¡åŠ¹ï¼ˆè¨­å®šã«ã‚ˆã‚Šï¼‰');
        return;
      }
      
      clearError();
      console.log('[useAudioEngine] éŸ³ç¨‹æ¤œå‡ºé–‹å§‹');
      
      // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³åˆæœŸåŒ–
      await initializeMicrophone();
      
      // ãƒ•ã‚§ãƒ¼ã‚ºç§»è¡Œãƒ»æ¤œå‡ºé–‹å§‹
      setPhase(AudioSystemPhase.SCORING_PHASE);
      startPitchDetectionLoop();
      
      console.log('[useAudioEngine] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³ç¨‹æ¤œå‡ºé–‹å§‹');
      
    } catch (err) {
      setPhase(AudioSystemPhase.IDLE);
      handleError(`éŸ³ç¨‹æ¤œå‡ºé–‹å§‹ã‚¨ãƒ©ãƒ¼: ${err}`);
    }
  }, [clearError, handleError, initializeMicrophone, startPitchDetectionLoop]);
  
  // éŸ³ç¨‹æ¤œå‡ºåœæ­¢
  const stopPitchDetection = useCallback(() => {
    try {
      console.log('[useAudioEngine] éŸ³ç¨‹æ¤œå‡ºåœæ­¢');
      
      // animationFrameåœæ­¢
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
      
      // æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
      setCurrentPitch(null);
      setCorrectedPitch(null);
      setConfidence(0);
      
      // å€éŸ³è£œæ­£ã‚·ã‚¹ãƒ†ãƒ ã®ãƒªã‚»ãƒƒãƒˆ
      previousFrequencyRef.current = null;
      stabilityBufferRef.current = [];
      
      // ãƒ•ã‚§ãƒ¼ã‚ºãƒªã‚»ãƒƒãƒˆ
      if (phase === AudioSystemPhase.SCORING_PHASE) {
        setPhase(AudioSystemPhase.IDLE);
      }
      
      // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ - å‘¼ã³å‡ºã—å´ã§åˆ¶å¾¡å¯èƒ½ï¼‰
      // disposeMicrophone(); // å¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆè§£é™¤
      
    } catch (err) {
      handleError(`éŸ³ç¨‹æ¤œå‡ºåœæ­¢ã‚¨ãƒ©ãƒ¼: ${err}`);
    }
  }, [phase, handleError]);
  
  return {
    // åŸºéŸ³å†ç”Ÿæ©Ÿèƒ½
    playBaseTone,
    stopBaseTone,
    
    // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³æ©Ÿèƒ½
    startPitchDetection,
    stopPitchDetection,
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º
    currentPitch,
    correctedPitch,
    confidence,
    
    // çŠ¶æ…‹ç®¡ç†
    isPlaying,
    phase,
    error
  };
}